<html>
<head>
  <title>02算法</title>
  <basefont face="微软雅黑" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="Evernote Windows/307027 (zh-CN, DDL); Windows/6.1.0 (Win32);"/>
  <style>
    body, td {
      font-family: 微软雅黑;
      font-size: 10pt;
    }
  </style>
</head>
<body>
<a name="966"/>
<h1>02算法</h1>

<div>
<span><div><div>一、<span style="font-size: 21px; color: rgb(28, 51, 135); font-weight: bold;">linear regression</span></div><table style="table-layout: fixed; border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 295px;"></col><col style="width: 289px;"></col></colgroup><tbody><tr><td style="border: 1px solid rgb(211, 211, 211); width: 295px; padding: 8px;"><div><span style="font-size: 48px;"><span style="font-size: 48px;">y = mx + b</span></span>,</div><div>where m is the slope and b is the y-intercept.</div></td><td style="border: 1px solid rgb(211, 211, 211); width: 289px; padding: 8px;"><div><br/></div></td></tr><tr><td style="border: 1px solid rgb(211, 211, 211); width: 295px; padding: 8px;"><div><img src="02算法_files/Image.png" type="image/png" data-filename="Image.png" style="height:auto;" width="350"/></div></td><td style="border: 1px solid rgb(211, 211, 211); width: 289px; padding: 8px;"><div>       线性回归，是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，运用十分广泛。其表达形式为y = w'x+e，e为误差服从均值为0的正态分布。</div><div>      必须要有比较精确方式决定理想的线性方程式。可以要求误差平方的总和为最小，做为决定理想的线性方程式的准则，这样的方法就称为最小平方误差(least squares error)或是线性回归。</div></td></tr><tr><td style="border: 1px solid rgb(211, 211, 211); width: 295px; padding: 8px;"><div><img src="02算法_files/Image [1].png" type="image/png" data-filename="Image.png" style="height:auto;" width="353"/></div></td><td style="border: 1px solid rgb(211, 211, 211); width: 289px; padding: 8px;"><div><br/></div></td></tr><tr><td style="border: 1px solid rgb(211, 211, 211); width: 295px; padding: 8px;"><div><a href="http://blog.csdn.net/ytdxyhz/article/details/51730995">http://blog.csdn.net/ytdxyhz/article/details/51730995</a></div></td><td style="border: 1px solid rgb(211, 211, 211); width: 289px; padding: 8px;"><div><br/></div></td></tr><tr><td style="border: 1px solid rgb(211, 211, 211); width: 295px; padding: 8px;"><div><img src="02算法_files/Image [2].png" type="image/png" data-filename="Image.png" style="height:auto;" width="325"/></div><div><span style="font-size: 18px;">        真实数据的Yi与回归方程估算出来的Yi-head的之间的差的和</span></div><div><span style="font-size: 18px;">真实数据的Yi与平均出来的Yi-head的之间的差的和</span></div></td><td style="border: 1px solid rgb(211, 211, 211); width: 289px; padding: 8px;"><div>可决系数的计算式： 回归平方和（SSR）在总变差（SST）中所占的比重称为可决系数， 可决系数可以作为综合度量回归模型对样本观测值<a href="http://baike.baidu.com/item/%E6%8B%9F%E5%90%88%E4%BC%98%E5%BA%A6" target="_blank">拟合优度</a>的度量指标。可决系数越大，说明在<a href="http://baike.baidu.com/item/%E6%80%BB%E5%8F%98%E5%B7%AE" target="_blank">总变差</a>中由模型作出了解释的部分占的比重越大，模型拟合优度越好。反之可决系数小，说明模型对样本观测值的拟合程度越差。</div><div>The equation is essentially 1 minus the division of the squared error of the regression line and the squared error of the mean y line.</div></td></tr></tbody></table><div><br/></div><div><br/></div><div><span style="font-size: 21px; color: rgb(28, 51, 135); font-weight: bold;">二、K Nearest Neighbors</span></div><table style="table-layout: fixed; border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 289px;"></col><col style="width: 289px;"></col></colgroup><tbody><tr><td style="border: 1px solid rgb(211, 211, 211); width: 289px; padding: 8px;"><div><a href="https://en.wikipedia.org/wiki/Euclidean_distance" style="font-weight: bold;">Euclidean Distance</a></div><div><img src="02算法_files/Image [3].png" type="image/png" data-filename="Image.png" style="height: auto;"/></div></td><td style="border: 1px solid rgb(211, 211, 211); width: 289px; padding: 8px;"><div>plot1 = [1,3]</div><div>plot2 = [2,5]</div><div>euclidean_distance = sqrt( (plot1[0]-plot2[0])**2 + (plot1[1]-plot2[1])**2 )</div></td></tr></tbody></table><div><br/></div><div><span style="font-size: 21px;"><span style="font-weight: bold; font-size: 21px; color: rgb(28, 51, 135);">三、SVM（支持向量机）</span></span></div><div><br/></div><div><a href="http://www.dataguru.cn/thread-371987-1-1.html">http://www.dataguru.cn/thread-371987-1-1.html</a></div><table style="table-layout: fixed; border-collapse: collapse; min-width: 100%;"><colgroup><col style="width: 295px;"></col><col style="width: 295px;"></col></colgroup><tbody><tr><td style="border: 1px solid rgb(211, 211, 211); width: 295px; padding: 8px;"><div><img src="02算法_files/Image [4].png" type="image/png" data-filename="Image.png" style="height: auto;"/></div></td><td style="border: 1px solid rgb(211, 211, 211); width: 295px; padding: 8px;"><div><br/></div><div style="text-align: left;"><span style="color: rgb(51, 51, 51); font-family: Arial;">    在超平面w*x+b=0确定的情况下，|w*x+b|能够表示点x到距离超平面的远近，而通过观察w*x+b的符号与类标记y的符号是否一致可判断分类是否正确，所以，可以用(y*(w*x+b))的正负性来判定或表示分类的正确性。于此，我们便引出了函数间隔（functional margin）的概念。</span></div><div style="text-align: left;"><span style="color: rgb(51, 51, 51); font-family: Arial;">    定义函数间隔（用<img src="02算法_files/Image.jpg" type="image/jpeg" data-filename="Image.jpg" border="0" style="height: auto;" width="20"/>表示）为：</span></div><div style="text-align: left;"><span style="color: rgb(51, 51, 51); font-family: Arial;">                                               <img src="02算法_files/Image [1].jpg" type="image/jpeg" data-filename="Image.jpg" border="0" style="height: auto;" width="200"/></span></div><div><br/></div><div style="text-align: left;"><span style="color: rgb(51, 51, 51); font-family: Arial;">便为超平面(w, b)关于训练数据集T的函数间隔：</span></div><div style="text-align: left; margin-left: 80px;">            <img src="02算法_files/Image [2].jpg" type="image/jpeg" data-filename="Image.jpg" border="0" style="height: auto;" width="20"/>= <span style="font-weight: bold;">min<img src="02算法_files/Image [3].jpg" type="image/jpeg" data-filename="Image.jpg" border="0" style="height: auto;" width="20"/></span>i  (i=1，...n)</div></td></tr><tr><td style="border: 1px solid rgb(211, 211, 211); width: 295px; padding: 8px;"><div><img src="02算法_files/Image [5].png" type="image/png" data-filename="Image.png" style="height: auto;"/></div></td><td style="border: 1px solid rgb(211, 211, 211); width: 295px; padding: 8px;"><div><br/></div><div style="text-align: left;"><span style="color: rgb(51, 51, 51); font-family: Arial;">事实上，我们可以对法向量w加些约束条件，从而引出真正定义点到超平面的距离--几何间隔（geometrical margin）的概念。</span></div><div style="text-align: left;"><span style="color: rgb(51, 51, 51); font-family: Arial;">    假定对于一个点 x ，令其垂直投影到超平面上的对应点为 x0 ，w 是垂直于超平面的一个向量，<img src="02算法_files/Image [4].jpg" type="image/jpeg" data-filename="Image.jpg" border="0" style="height: auto;" width="17"/>为样本x到分类间隔的距离，</span></div></td></tr><tr><td style="border: 1px solid rgb(211, 211, 211); width: 295px; padding: 8px;"><div><img src="02算法_files/Image [6].png" type="image/png" data-filename="Image.png" style="height: auto;"/></div><div><img src="02算法_files/Image [7].png" type="image/png" data-filename="Image.png" style="height: auto;"/>            <img src="02算法_files/Image [8].png" type="image/png" data-filename="Image.png" style="height: auto;"/></div><div><br/></div><div><img src="02算法_files/Image [9].png" type="image/png" data-filename="Image.png" style="height: auto;"/></div></td><td style="border: 1px solid rgb(211, 211, 211); width: 295px; padding: 8px;"><div><span style="color: rgb(51, 51, 51); font-family: Arial;">从上述函数间隔和几何间隔的定义可以看出：几何间隔就是函数间隔除以||w||，而且函数间隔y*(wx+b) = y*f(x)实际上就是|f(x)|，只是人为定义的一个间隔度量，而几何间隔|f(x)|/||w||才是直观上的点到超平面的距离。</span></div></td></tr></tbody></table><div><br/></div><div><br/></div><div style="text-align: center;"><font style="color: rgb(28, 51, 135); font-size: 24pt;"><b>四、<span style="line-height: 1.45;">Logistic回归</span></b></font></div><div style="text-align: center;"><br/></div><div><font style="font-size: 18pt; color: rgb(28, 51, 135);">梯度上升算法</font></div><div><br/></div><div><img src="02算法_files/Image [10].png" type="image/png" data-filename="Image.png" width="280"/></div><div><br/></div><div><br/></div><h2><span style="font-weight: normal;"><font style="font-size: 18pt; color: rgb(28, 51, 135);">改进的随机梯度上升算法</font></span></h2><div><font style="font-size: 12pt; color: rgb(173, 0, 0);"><b>只用一个样本点去更新回归系数</b></font></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div></div></span>
</div></body></html> 