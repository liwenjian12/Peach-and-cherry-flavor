<html>
<head>
  <title>02反向传导算法</title>
  <basefont face="微软雅黑" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="Evernote Windows/307027 (zh-CN, DDL); Windows/6.1.0 (Win32);"/>
  <style>
    body, td {
      font-family: 微软雅黑;
      font-size: 10pt;
    }
  </style>
</head>
<body>
<a name="1127"/>
<h1>02反向传导算法</h1>

<div>
<span><div><span style="color: rgb(20, 113, 145);"><span style="font-size: 21px;">反向传导算法</span></span></div><div><br/></div><div>假设我们有一个固定样本集 ，它包含  个样例。我们可以用批量梯度下降法来求解神经网络。具体来讲，对于单个样例 ，其代价函数为：</div><div><img src="02反向传导算法_files/029cdd402b83ee43c7e9a900dccd675a.png" type="image/png" data-filename="029cdd402b83ee43c7e9a900dccd675a.png" style="height: auto;"/></div><div>这是一个（二分之一的）方差代价函数。给定一个包含  个样例的数据集，我们可以定义整体代价函数为：</div><div><img src="02反向传导算法_files/4539f5f00edca977011089b902670513.png" type="image/png" data-filename="4539f5f00edca977011089b902670513.png" style="height: auto;"/></div><div><br/></div><div>以上关于<img src="02反向传导算法_files/8e94ae776ae14b36b3af183726ababb9.png" type="image/png" data-filename="8e94ae776ae14b36b3af183726ababb9.png" style="height: auto;"/>定义中的第一项是一个均方差项。第二项是一个规则化项（也叫<b>权重衰减项</b>），其目的是减小权重的幅度，防止过度拟合。</div><div><br/></div><div>[注：通常权重衰减的计算并不使用偏置项 <img src="02反向传导算法_files/4c786c16575b63bbb554254725b6b648.png" type="image/png" data-filename="4c786c16575b63bbb554254725b6b648.png" style="height: auto;"/>，比如我们在<img src="02反向传导算法_files/8e94ae776ae14b36b3af183726ababb9 [1].png" type="image/png" data-filename="8e94ae776ae14b36b3af183726ababb9.png" style="height: auto;"/>  的定义中就没有使用。一般来说，将偏置项包含在权重衰减项中只会对最终的神经网络产生很小的影响。如果你在斯坦福选修过CS229（机器学习）课程，或者在YouTube上看过课程视频，你会发现这个权重衰减实际上是课上提到的贝叶斯规则化方法的变种。在贝叶斯规则化方法中，我们将高斯先验概率引入到参数中计算MAP（极大后验）估计（而不是极大似然估计）。]</div><div><b><br/></b></div><div><b>权重衰减参数</b><img src="02反向传导算法_files/ddf8905bd6bfeba5cfd2936466d4139e.png" type="image/png" data-filename="ddf8905bd6bfeba5cfd2936466d4139e.png" style="height: auto;"/>用于控制公式中两项的相对重要性。在此重申一下这两个复杂函数的含义：<img src="02反向传导算法_files/67b844ee86f32de53bab325b8a76a94f.png" type="image/png" data-filename="67b844ee86f32de53bab325b8a76a94f.png" style="height: auto;"/> 是针对单个样例计算得到的方差代价函数；<img src="02反向传导算法_files/8e94ae776ae14b36b3af183726ababb9 [2].png" type="image/png" data-filename="8e94ae776ae14b36b3af183726ababb9.png" style="height: auto;"/> 是整体样本代价函数，它包含权重衰减项。</div><div><br/></div><div>以上的代价函数经常被用于分类和回归问题。在分类问题中，我们用 <b>y=0  或 1</b> ，来代表两种类型的标签（回想一下，这是因为 sigmoid激活函数的值域为<span style="font-size: 16px;"><b>[0,1]</b></span> ；如果我们使用双曲正切型激活函数，那么应该选用 <b>-1 和 +1</b> 作为标签）。对于回归问题，我们首先要变换输出值域（译者注：也就是 y ），以保证其范围为 <b><span style="font-size: 16px;">[0,1]</span></b>  （同样地，如果我们使用双曲正切型激活函数，要使输出值域为 <span style="font-size: 16px;"><b>[-1,1]</b></span>）。</div><div><br/></div><div><span style="color: rgb(255, 0, 0);">我们的目标是针对参数 <span style="font-size: 16px;"><b>W 和 b</b></span> 来求其函数<img src="02反向传导算法_files/8e94ae776ae14b36b3af183726ababb9 [3].png" type="image/png" data-filename="8e94ae776ae14b36b3af183726ababb9.png" style="height: auto;"/>  的最小值。为了求解神经网络，我们需要将每一个参数<img src="02反向传导算法_files/dfe43c64e3c42ea4ff1774fc82b87805.png" type="image/png" data-filename="dfe43c64e3c42ea4ff1774fc82b87805.png" style="height: auto;"/>  和<img src="02反向传导算法_files/4c786c16575b63bbb554254725b6b648 [1].png" type="image/png" data-filename="4c786c16575b63bbb554254725b6b648.png" style="height: auto;"/>  初始化为一个很小的、接近零的随机值（比如说，使用正态分布  <img src="02反向传导算法_files/b19e677536c9c7b9da542e4d36c07001.png" type="image/png" data-filename="b19e677536c9c7b9da542e4d36c07001.png" style="height: auto;"/>生成的随机值，其中  <img src="02反向传导算法_files/a8eae7b5e90c024c40de690158e0e6b1.png" type="image/png" data-filename="a8eae7b5e90c024c40de690158e0e6b1.png" style="height: auto;"/>设置为  <img src="02反向传导算法_files/60ec211aca4ac585f1c0ef4de8e08f39.png" type="image/png" data-filename="60ec211aca4ac585f1c0ef4de8e08f39.png" style="height: auto;"/>）</span>，之后对目标函数使用诸如批量梯度下降法的最优化算法。因为  是一个非凸函数，梯度下降法很可能会收敛到局部最优解；但是在实际应用中，梯度下降法通常能得到令人满意的结果。最后，需要再次强调的是，要将参数进行随机初始化，而不是全部置为 0 。随机初始化的目的是使<b>对称失效</b>。</div><div><br/></div><div>梯度下降法中每一次迭代都按照如下公式对参数 <b>W  和 b</b> 进行更新：</div><div><img src="02反向传导算法_files/6fe7c74511cd6d49a4c9cb6de2afdc33.png" type="image/png" data-filename="6fe7c74511cd6d49a4c9cb6de2afdc33.png" style="height: auto;"/></div><div><br/></div><div>其中 <img src="02反向传导算法_files/7eaa466003e48c1c96824a2edf3de038.png" type="image/png" data-filename="7eaa466003e48c1c96824a2edf3de038.png" style="height: auto;"/> 是学习速率。<span style="color: rgb(250, 122, 0);">其中关键步骤是计算偏导数。</span></div><div><span style="color: rgb(106, 0, 129);"><span style="font-size: 16px;">我们现在来讲一下反向传播算法，它是计算偏导数的一种有效方法。</span></span></div><div><br/></div><div>我们首先来讲一下如何使用反向传播算法来计算 <img src="02反向传导算法_files/5fb8e62e296ad365a076617b04d66d03.png" type="image/png" data-filename="5fb8e62e296ad365a076617b04d66d03.png" style="height: auto;"/> 和<img src="02反向传导算法_files/ca49d387f9ead91008f9688b3880e91b.png" type="image/png" data-filename="ca49d387f9ead91008f9688b3880e91b.png" style="height: auto;"/> ，这两项是单个样例 <img src="02反向传导算法_files/untitled.png" type="image/png" data-filename="untitled.png" style="height: auto;"/> 的代价函数 <img src="02反向传导算法_files/67b844ee86f32de53bab325b8a76a94f [1].png" type="image/png" data-filename="67b844ee86f32de53bab325b8a76a94f.png" style="height: auto;"/> 的偏导数。一旦我们求出该偏导数，就可以推导出整体代价函数<img src="02反向传导算法_files/8e94ae776ae14b36b3af183726ababb9 [4].png" type="image/png" data-filename="8e94ae776ae14b36b3af183726ababb9.png" style="height: auto;"/>  的偏导数：</div><div><br/></div><div><img src="02反向传导算法_files/1.png" type="image/png" data-filename="1.png" style="height: auto;"/></div><div><br/></div><div>以上两行公式稍有不同，第一行比第二行多出一项，是因为<span style="background-color: rgb(255, 250, 165);-evernote-highlight:true;"><span style="color: rgb(26, 144, 185);">权重衰减是作用于 W 而不是 b</span> 。</span></div><div><span style="background-color: rgb(255, 250, 165);-evernote-highlight:true;"><br/></span></div><div><span style="background-color: rgb(255, 250, 165);-evernote-highlight:true;"><img src="02反向传导算法_files/捕获.PNG" type="image/png" data-filename="捕获.PNG" style="height:auto;" width="1111"/><br/></span></div><div><br/></div><ul><li> <img src="02反向传导算法_files/Image.png" type="image/png" data-filename="Image.png" style="height: auto;"/></li><li><img src="02反向传导算法_files/Image [1].png" type="image/png" data-filename="Image.png" style="height: auto;"/></li></ul><div> </div><div> </div><ul><li><img src="02反向传导算法_files/Image [2].png" type="image/png" data-filename="Image.png" style="height: auto;"/></li><li><img src="02反向传导算法_files/Image [3].png" type="image/png" data-filename="Image.png"/></li><li><img src="02反向传导算法_files/Image [4].png" type="image/png" data-filename="Image.png"/></li></ul><div><br/></div><div><br/></div><div><img src="02反向传导算法_files/Image [5].png" type="image/png" data-filename="Image.png"/></div></span>
</div></body></html> 